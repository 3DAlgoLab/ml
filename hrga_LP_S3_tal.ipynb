{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Milestone 3: Training a Supervised Image Classifier on the Melanoma Dataset using Transfer Learning\n","\n"," In machine learning, there are no ready-to-use recipes. Certain approaches have been found to work well for certain cases, but in the end, much of it comes down to trial and error. [Occam’s razor](https://en.wikipedia.org/wiki/Occam%27s_razor) (the principle roughly summarized as “the simplest solution is usually the best one”) suggests starting from the most basic method, and building up on top of it until we get the performance we want. Keeping track of improvements we get at each step also helps us justify our efforts!\n","\n"," ## Part A: The Data\n","\n"," Here I reuse the Dataset code that I wrote for Milestone 2.\n","\n"," Even in the extreme situation of only having 200 labeled samples available for training, we still have to set aside some number of them for the validation set. The fewer training samples we have, the greater the risk of overfitting, which makes having a validation set absolutely essential. It is up to you to decide what fraction of the precious few labeled samples to keep for validation purposes; I set it at 30% or 60 images, as anything smaller than that would likely result in a major val set overfitting problem."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from os import listdir\n","from os.path import join\n","\n","from PIL import Image\n","import random\n","\n","import matplotlib.pyplot as plt\n","\n","\n","import numpy as np\n","import copy\n","\n","import torch \n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import  models\n","import torch.nn.functional as F\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Current Device: \", device)\n","\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define a function to set the seed. This will make results reproducible.\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","            \n","    # [your code here]\n","\n","# Define a function to check if a file is actually an image.\n","def is_image(filename):\n","    if isinstance(filename, str):\n","        filename = Path(filename)\n","    return filename.suffix in ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Some test for Path \n","\n","dir_labeled = \"./data/MelanomaDetectionLabeled/labeled/\"\n","dir_test  = \"./data/MelanomaDetectionLabeled/test/\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LabeledDataset(Dataset):\n","\n","    def __init__(self, dir_path, transform=None):\n","        \"\"\"\n","        Args:\n","            dir_path (string): Directory containing the images.\n","            transform (optional): Optional transform to be applied\n","                on an image.\n","        \"\"\"\n","        \n","        # The list of all the image file names (but not the images themselves!) will be read\n","        # when the Dataset object is initialized\n","        p = Path(dir_path).resolve()\n","        self.img_path_list = [f for f in p.iterdir() if is_image(f)]\n","        self.transform = transform\n","        \n","        \n","    def __len__(self):\n","        return len(self.img_path_list)    \n","\n","    def __getitem__(self, idx):\n","        \n","        # Here is where the image actually gets read:\n","        img_path = self.img_path_list[idx]\n","        # img = read_image(str(img_path)).type(torch.float32)/255.0        \n","        img = Image.open(img_path)\n","        if self.transform:\n","            img = self.transform(img)\n","            \n","        img = np.asarray(img)\n","        label = int(img_path.stem.split('_')[1])\n","\n","        return img, label\n","    \n","    \n","# test code \n","\n","labeled_set = LabeledDataset(dir_labeled)\n","\n","print('Number of image is {}'.format(len(labeled_set)))\n","print('Label:', labeled_set[0][1])\n","\n","labeled_set[100][0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labeled_loader = DataLoader(labeled_set, batch_size=4, shuffle=True)\n","\n","for batch in labeled_loader:\n","    print(batch[0].shape)\n","    print(batch[1].shape)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","for batch_idx, batch in enumerate(labeled_loader):    \n","    if batch_idx > 0:\n","        break \n","    \n","    print(\"Batch labels\", batch[1].data)\n","    image_grid = torchvision.utils.make_grid(batch[0], nrow=4)\n","    plt.imshow(image_grid.permute(1, 2, 0))\n","    plt.pause(0.05)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Choose some transformations\n","rotation = transforms.RandomChoice([transforms.RandomRotation([-3, 3]), \n","                                    transforms.RandomRotation([87, 93]), \n","                                    transforms.RandomRotation([177,183]),\n","                                    transforms.RandomRotation([267, 273])])\n","augmentation = transforms.Compose([transforms.RandomHorizontalFlip(), \n","                                   transforms.RandomVerticalFlip(), \n","                                   rotation])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Instantiate the Label Dataset class for training\n","labeled_set = LabeledDataset(dir_labeled, transform=transforms.Compose([transforms.ToTensor(), augmentation]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Randomly split the dataset (don't forget to set the seed!)\n","set_seed(123)\n","\n","train_set, val_set = torch.utils.data.random_split(labeled_set, [0.7, 0.3])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Instantiate the LabeledDataset class for testing\n","test_set = LabeledDataset(dir_test, transform=transforms.ToTensor())\n","\n","# Print the number of images in the train, validation and test sets\n","print(\"Number of images in the training set: \", len(train_set))\n","print(\"Number of images in the validation set: \", len(val_set))\n","print(\"Number of images in the test set: \", len(test_set))\n","\n","# Write data loaders for training, validation and testing\n","# Since we have so few samples for the fully supervised part, you can use the entire set \n","# at each training iteration, rather than separate it into mini-batches:\n","\n","# [your code here]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labeled_set = LabeledDataset(dir_labeled, transform=transforms.ToTensor())\n","img = labeled_set[0][0]\n","print(img)"]}],"metadata":{"kernelspec":{"display_name":"cam","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d573937473b88991df033c8e7cd2a78641f250341eab636e267870441ea13f65"}}},"nbformat":4,"nbformat_minor":2}
